# @package _global_
defaults:
  - _self_
  # colored logs for more readability
#   - override hydra/job_logging: colorlog
#   - override hydra/hydra_logging: colorlog

# hydra:
#       run:
#           dir: logs/${model_config.exp_name}/${env_config.env_id}/${scheduler_config.scheduling_strategy}/${now:%Y-%m-%d-%H-%M-%S}

env_type: mani_skill
env_config:
  obs_mode: rgb
  control_mode: pd_ee_delta_pose
  render_mode: rgb_array
  sim_backend: gpu
  reward_mode: dense
  env_id: PickCube-v1
  num_envs: 32
  num_steps: 50
  include_state: false
  partial_reset: true
  use_render_camera_as_input: False
  image_height: 256
  image_width: 256

scheduler_config:
  scheduling_strategy: octo_epsilon
  epsilon: 0.5
  policy_trust_length: 5
  decrease_until_global_step: 200_000
device: cuda

evaluate: true
eval_freq: 1_000_000 # for now is ignored we do not evaluate only save ckpts 
save_train_videos: true
save_eval_videos: true
save_train_video_freq: 4800
model_type: ppo_rgb
path_to_loaded_model: null
ckpt_save_frequency: 4800

# /home/piscenco/logs/octo_reward_based_temp10/PickCube-v1/octo_reward_based/2024-11-17-17-19-19/octo_reward_based_temp10/model_ckpt/ckpt_72.pt
model_config:
  exp_name: 004_experiment_ppo_octo_epsilon_0_5
  model_device: cuda
  seed: 13
  num_steps: ${env_config.num_steps}
  num_envs: ${env_config.num_envs}
  include_state: false
  total_timesteps: 100_000
  learning_rate: 0.0003
  num_minibatches: 10
  actor_type: BasicActor
  actor_activation_layer: ReLU
  critic_type: BasicCritic
  critic_activation_layer: ReLU
  clip_coef: 1

